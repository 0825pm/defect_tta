"""
============================================================================
Severstal Steel Defect Detection - ë‹¤ì¤‘ ë¶ˆëŸ‰ Co-occurrence ë¶„ì„
============================================================================

ë°ì´í„° êµ¬ì¡°:
    train.csv: ImageId, ClassId, EncodedPixels
    - í•œ ì´ë¯¸ì§€ê°€ ì—¬ëŸ¬ í–‰ì— ìˆìœ¼ë©´ ë‹¤ì¤‘ ë¶ˆëŸ‰
    - ClassId: 1, 2, 3, 4 (4ê°œ ë¶ˆëŸ‰ ìœ í˜•)
    - EncodedPixels: RLE í˜•ì‹ ë§ˆìŠ¤í¬ (ì—†ìœ¼ë©´ í•´ë‹¹ í´ë˜ìŠ¤ ë¶ˆëŸ‰ ì—†ìŒ)

ì‚¬ìš©ë²•:
    python analyze_severstal.py --data_root /path/to/severstal_data

ì¶œë ¥:
    - ë‹¤ì¤‘ ë¶ˆëŸ‰ í†µê³„
    - Co-occurrence Matrix
    - ì¡°ê±´ë¶€ í™•ë¥  P(Class_j | Class_i)
    - ì‹œê°í™” íˆíŠ¸ë§µ

============================================================================
"""

import os
import argparse
import json
import numpy as np
import pandas as pd
from collections import defaultdict
from itertools import combinations
import warnings
warnings.filterwarnings('ignore')

# ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    HAS_PLOT = True
except ImportError:
    HAS_PLOT = False
    print("âš ï¸  matplotlib/seaborn ì—†ìŒ - ì‹œê°í™” ê±´ë„ˆëœ€")


# =============================================================================
# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# =============================================================================
def load_and_preprocess(csv_path):
    """
    train.csv ë¡œë“œ ë° ì „ì²˜ë¦¬
    """
    print(f"ğŸ“‚ ë°ì´í„° ë¡œë“œ: {csv_path}")
    
    df = pd.read_csv(csv_path)
    print(f"   ì´ í–‰ ìˆ˜: {len(df):,}")
    print(f"   ì»¬ëŸ¼: {list(df.columns)}")
    
    # ê²°ì¸¡ì¹˜ í™•ì¸
    print(f"\nğŸ“Š ê²°ì¸¡ì¹˜ í™•ì¸:")
    print(df.isnull().sum())
    
    # ë¶ˆëŸ‰ì´ ìˆëŠ” í–‰ë§Œ í•„í„°ë§ (EncodedPixelsê°€ ìˆëŠ” ê²½ìš°)
    df_defect = df[df['EncodedPixels'].notna()].copy()
    print(f"\n   ë¶ˆëŸ‰ì´ ìˆëŠ” í–‰: {len(df_defect):,}")
    
    return df, df_defect


def analyze_multi_defect(df_defect):
    """
    ì´ë¯¸ì§€ë³„ ë‹¤ì¤‘ ë¶ˆëŸ‰ ë¶„ì„
    """
    print("\n" + "=" * 60)
    print("ğŸ”¬ ë‹¤ì¤‘ ë¶ˆëŸ‰ ë¶„ì„")
    print("=" * 60)
    
    # ì´ë¯¸ì§€ë³„ ë¶ˆëŸ‰ í´ë˜ìŠ¤ ì§‘ê³„
    image_defects = df_defect.groupby('ImageId')['ClassId'].apply(list).reset_index()
    image_defects['num_defects'] = image_defects['ClassId'].apply(len)
    image_defects['defect_set'] = image_defects['ClassId'].apply(lambda x: tuple(sorted(set(x))))
    
    # í†µê³„
    total_images = len(image_defects)
    single_defect = (image_defects['num_defects'] == 1).sum()
    multi_defect = (image_defects['num_defects'] >= 2).sum()
    
    print(f"\nğŸ“Š ê¸°ë³¸ í†µê³„:")
    print(f"   ì´ ë¶ˆëŸ‰ ì´ë¯¸ì§€: {total_images:,}")
    print(f"   ë‹¨ì¼ ë¶ˆëŸ‰ ì´ë¯¸ì§€: {single_defect:,} ({single_defect/total_images*100:.1f}%)")
    print(f"   ë‹¤ì¤‘ ë¶ˆëŸ‰ ì´ë¯¸ì§€: {multi_defect:,} ({multi_defect/total_images*100:.1f}%)")
    
    # ë¶ˆëŸ‰ ê°œìˆ˜ë³„ ë¶„í¬
    print(f"\nğŸ“Š ì´ë¯¸ì§€ë‹¹ ë¶ˆëŸ‰ ê°œìˆ˜ ë¶„í¬:")
    defect_count_dist = image_defects['num_defects'].value_counts().sort_index()
    for num, count in defect_count_dist.items():
        ratio = count / total_images * 100
        marker = "  â† ë‹¤ì¤‘ ë¶ˆëŸ‰" if num >= 2 else ""
        print(f"   {num}ê°œ ë¶ˆëŸ‰: {count:,} ({ratio:.1f}%){marker}")
    
    # í´ë˜ìŠ¤ë³„ ì¶œí˜„ ë¹ˆë„
    print(f"\nğŸ“Š í´ë˜ìŠ¤ë³„ ì¶œí˜„ ë¹ˆë„:")
    class_counts = df_defect['ClassId'].value_counts().sort_index()
    for cls, count in class_counts.items():
        ratio = count / total_images * 100
        print(f"   Class {cls}: {count:,} ({ratio:.1f}%)")
    
    return image_defects


# =============================================================================
# Co-occurrence ë¶„ì„
# =============================================================================
def build_cooccurrence_matrix(image_defects):
    """
    Co-occurrence Matrix ìƒì„±
    """
    print("\n" + "=" * 60)
    print("ğŸ“Š Co-occurrence Matrix ìƒì„±")
    print("=" * 60)
    
    classes = [1, 2, 3, 4]
    n = len(classes)
    
    # í–‰ë ¬ ì´ˆê¸°í™”
    cooccur_matrix = np.zeros((n, n), dtype=int)
    
    # í´ë˜ìŠ¤ë³„ ì¶œí˜„ íšŸìˆ˜ (ëŒ€ê°ì„ )
    class_counts = defaultdict(int)
    
    # Co-occurrence íšŸìˆ˜ (ë¹„ëŒ€ê°ì„ )
    cooccur_counts = defaultdict(int)
    
    for _, row in image_defects.iterrows():
        defects = list(set(row['ClassId']))
        
        # í´ë˜ìŠ¤ë³„ ì¹´ìš´íŠ¸
        for d in defects:
            class_counts[d] += 1
        
        # ë™ì‹œ ë°œìƒ ì¹´ìš´íŠ¸
        if len(defects) >= 2:
            for d1, d2 in combinations(sorted(defects), 2):
                cooccur_counts[(d1, d2)] += 1
    
    # í–‰ë ¬ ì±„ìš°ê¸°
    for i, c1 in enumerate(classes):
        cooccur_matrix[i, i] = class_counts[c1]  # ëŒ€ê°ì„ 
        for j, c2 in enumerate(classes):
            if i < j:
                count = cooccur_counts.get((c1, c2), 0)
                cooccur_matrix[i, j] = count
                cooccur_matrix[j, i] = count  # ëŒ€ì¹­
    
    # DataFrame ë³€í™˜
    class_names = [f'Class_{c}' for c in classes]
    df_cooccur = pd.DataFrame(cooccur_matrix, index=class_names, columns=class_names)
    
    print("\nğŸ“Š Co-occurrence Matrix (ëŒ€ê°ì„  = í•´ë‹¹ í´ë˜ìŠ¤ ì´ ì¶œí˜„ íšŸìˆ˜):")
    print(df_cooccur)
    
    return df_cooccur, class_counts, cooccur_counts


def calculate_conditional_probability(class_counts, cooccur_counts):
    """
    ì¡°ê±´ë¶€ í™•ë¥  P(Class_j | Class_i) ê³„ì‚°
    """
    print("\n" + "=" * 60)
    print("ğŸ“Š ì¡°ê±´ë¶€ í™•ë¥  P(Col | Row)")
    print("=" * 60)
    
    classes = [1, 2, 3, 4]
    n = len(classes)
    
    cond_prob = np.zeros((n, n))
    
    for i, c_i in enumerate(classes):
        count_i = class_counts[c_i]
        if count_i == 0:
            continue
        
        for j, c_j in enumerate(classes):
            if i == j:
                cond_prob[i, j] = 1.0
            else:
                key = tuple(sorted([c_i, c_j]))
                cooccur = cooccur_counts.get(key, 0)
                cond_prob[i, j] = cooccur / count_i
    
    class_names = [f'Class_{c}' for c in classes]
    df_cond = pd.DataFrame(cond_prob, index=class_names, columns=class_names)
    
    print("\nğŸ“Š ì¡°ê±´ë¶€ í™•ë¥  í–‰ë ¬:")
    print(df_cond.round(3))
    
    return df_cond


def analyze_defect_combinations(image_defects):
    """
    ê°€ì¥ ë¹ˆë²ˆí•œ ë¶ˆëŸ‰ ì¡°í•© ë¶„ì„
    """
    print("\n" + "=" * 60)
    print("ğŸ”¥ ë¹ˆë²ˆí•œ ë¶ˆëŸ‰ ì¡°í•©")
    print("=" * 60)
    
    # ë‹¤ì¤‘ ë¶ˆëŸ‰ë§Œ í•„í„°
    multi_df = image_defects[image_defects['num_defects'] >= 2].copy()
    
    if len(multi_df) == 0:
        print("   ë‹¤ì¤‘ ë¶ˆëŸ‰ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì¡°í•©ë³„ ë¹ˆë„
    combo_counts = multi_df['defect_set'].value_counts()
    
    print(f"\n{'ì¡°í•©':<25} {'íšŸìˆ˜':<10} {'ë¹„ìœ¨':<10}")
    print("-" * 45)
    
    total_multi = len(multi_df)
    results = []
    
    for combo, count in combo_counts.head(15).items():
        ratio = count / total_multi * 100
        combo_str = ' + '.join([f'Class_{c}' for c in combo])
        print(f"{combo_str:<25} {count:<10} {ratio:.1f}%")
        results.append({
            'combination': combo,
            'combination_str': combo_str,
            'count': count,
            'ratio': ratio
        })
    
    return pd.DataFrame(results)


# =============================================================================
# ì‹œê°í™”
# =============================================================================
def plot_cooccurrence_heatmap(df_cooccur, output_dir):
    """Co-occurrence Matrix íˆíŠ¸ë§µ"""
    if not HAS_PLOT:
        return
    
    plt.figure(figsize=(8, 6))
    
    # ëŒ€ê°ì„  ë§ˆìŠ¤í¬
    mask = np.eye(len(df_cooccur), dtype=bool)
    
    sns.heatmap(df_cooccur, annot=True, fmt='d', cmap='YlOrRd',
                mask=mask, square=True, linewidths=0.5,
                cbar_kws={'label': 'Co-occurrence Count'})
    
    plt.title('Severstal Steel - Defect Co-occurrence Matrix', fontsize=14)
    plt.xlabel('Defect Class')
    plt.ylabel('Defect Class')
    plt.tight_layout()
    
    output_path = os.path.join(output_dir, 'cooccurrence_matrix.png')
    plt.savefig(output_path, dpi=150)
    plt.close()
    print(f"\nğŸ“Š ì €ì¥: {output_path}")


def plot_conditional_probability(df_cond, output_dir):
    """ì¡°ê±´ë¶€ í™•ë¥  íˆíŠ¸ë§µ"""
    if not HAS_PLOT:
        return
    
    plt.figure(figsize=(8, 6))
    
    sns.heatmap(df_cond, annot=True, fmt='.3f', cmap='Blues',
                square=True, linewidths=0.5, vmin=0, vmax=1,
                cbar_kws={'label': 'P(Column | Row)'})
    
    plt.title('Severstal Steel - Conditional Probability P(Col|Row)', fontsize=14)
    plt.xlabel('Defect Class (Target)')
    plt.ylabel('Defect Class (Given)')
    plt.tight_layout()
    
    output_path = os.path.join(output_dir, 'conditional_probability.png')
    plt.savefig(output_path, dpi=150)
    plt.close()
    print(f"ğŸ“Š ì €ì¥: {output_path}")


def plot_defect_distribution(image_defects, output_dir):
    """ë¶ˆëŸ‰ ë¶„í¬ ì‹œê°í™”"""
    if not HAS_PLOT:
        return
    
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    # 1. ì´ë¯¸ì§€ë‹¹ ë¶ˆëŸ‰ ê°œìˆ˜ ë¶„í¬
    defect_counts = image_defects['num_defects'].value_counts().sort_index()
    colors = ['steelblue' if x == 1 else 'coral' for x in defect_counts.index]
    
    axes[0].bar(defect_counts.index, defect_counts.values, color=colors)
    axes[0].set_xlabel('Number of Defects per Image')
    axes[0].set_ylabel('Number of Images')
    axes[0].set_title('Distribution of Defect Count per Image')
    axes[0].set_xticks(defect_counts.index)
    
    # ë¹„ìœ¨ í‘œì‹œ
    total = len(image_defects)
    for i, (x, y) in enumerate(zip(defect_counts.index, defect_counts.values)):
        axes[0].text(x, y + 50, f'{y/total*100:.1f}%', ha='center', fontsize=10)
    
    # 2. ë‹¨ì¼ vs ë‹¤ì¤‘ ë¶ˆëŸ‰ íŒŒì´ ì°¨íŠ¸
    single = (image_defects['num_defects'] == 1).sum()
    multi = (image_defects['num_defects'] >= 2).sum()
    
    axes[1].pie([single, multi], labels=['Single Defect', 'Multi-Defect'],
                autopct='%1.1f%%', colors=['steelblue', 'coral'],
                explode=[0, 0.05], startangle=90)
    axes[1].set_title('Single vs Multi-Defect Images')
    
    plt.tight_layout()
    output_path = os.path.join(output_dir, 'defect_distribution.png')
    plt.savefig(output_path, dpi=150)
    plt.close()
    print(f"ğŸ“Š ì €ì¥: {output_path}")


# =============================================================================
# ë©”ì¸ í•¨ìˆ˜
# =============================================================================
def main(data_root, output_dir):
    """
    ì „ì²´ ë¶„ì„ ì‹¤í–‰
    """
    print("=" * 70)
    print("ğŸ”¬ SEVERSTAL STEEL DEFECT - ë‹¤ì¤‘ ë¶ˆëŸ‰ CO-OCCURRENCE ë¶„ì„")
    print("=" * 70)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # CSV ê²½ë¡œ
    csv_path = os.path.join(data_root, 'train.csv')
    if not os.path.exists(csv_path):
        print(f"âŒ train.csvë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
        return
    
    # 1. ë°ì´í„° ë¡œë“œ
    df, df_defect = load_and_preprocess(csv_path)
    
    # 2. ë‹¤ì¤‘ ë¶ˆëŸ‰ ë¶„ì„
    image_defects = analyze_multi_defect(df_defect)
    
    # 3. Co-occurrence Matrix
    df_cooccur, class_counts, cooccur_counts = build_cooccurrence_matrix(image_defects)
    
    # 4. ì¡°ê±´ë¶€ í™•ë¥ 
    df_cond = calculate_conditional_probability(class_counts, cooccur_counts)
    
    # 5. ë¹ˆë²ˆí•œ ì¡°í•© ë¶„ì„
    df_combos = analyze_defect_combinations(image_defects)
    
    # 6. ì‹œê°í™”
    print("\n" + "=" * 60)
    print("ğŸ“Š ì‹œê°í™” ìƒì„±")
    print("=" * 60)
    
    plot_cooccurrence_heatmap(df_cooccur, output_dir)
    plot_conditional_probability(df_cond, output_dir)
    plot_defect_distribution(image_defects, output_dir)
    
    # 7. ê²°ê³¼ ì €ì¥
    print("\n" + "=" * 60)
    print("ğŸ’¾ ê²°ê³¼ ì €ì¥")
    print("=" * 60)
    
    # CSV ì €ì¥
    df_cooccur.to_csv(os.path.join(output_dir, 'cooccurrence_matrix.csv'))
    df_cond.to_csv(os.path.join(output_dir, 'conditional_probability.csv'))
    
    if df_combos is not None:
        df_combos.to_csv(os.path.join(output_dir, 'frequent_combinations.csv'), index=False)
    
    # ë‹¤ì¤‘ ë¶ˆëŸ‰ ì´ë¯¸ì§€ ìƒì„¸
    multi_images = image_defects[image_defects['num_defects'] >= 2].copy()
    multi_images['defect_str'] = multi_images['defect_set'].apply(
        lambda x: ', '.join([f'Class_{c}' for c in x])
    )
    multi_images[['ImageId', 'num_defects', 'defect_str']].to_csv(
        os.path.join(output_dir, 'multi_defect_images.csv'), index=False
    )
    
    # ìš”ì•½ JSON
    summary = {
        'total_defect_images': len(image_defects),
        'single_defect_images': int((image_defects['num_defects'] == 1).sum()),
        'multi_defect_images': int((image_defects['num_defects'] >= 2).sum()),
        'multi_defect_ratio': float((image_defects['num_defects'] >= 2).sum() / len(image_defects) * 100),
        'defect_count_distribution': image_defects['num_defects'].value_counts().to_dict(),
        'class_counts': {f'Class_{k}': int(v) for k, v in class_counts.items()},
        'cooccurrence_counts': {f'{k[0]}-{k[1]}': int(v) for k, v in cooccur_counts.items()}
    }
    
    with open(os.path.join(output_dir, 'summary.json'), 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"   âœ… cooccurrence_matrix.csv")
    print(f"   âœ… conditional_probability.csv")
    print(f"   âœ… frequent_combinations.csv")
    print(f"   âœ… multi_defect_images.csv")
    print(f"   âœ… summary.json")
    
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ëŠ” '{output_dir}/' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ì—°êµ¬ ì‹œì‚¬ì  ì¶œë ¥
    print("\n" + "=" * 70)
    print("ğŸ’¡ ì—°êµ¬ ì‹œì‚¬ì ")
    print("=" * 70)
    
    multi_ratio = summary['multi_defect_ratio']
    print(f"\n1. ë‹¤ì¤‘ ë¶ˆëŸ‰ ë¹„ìœ¨: {multi_ratio:.1f}%")
    
    if multi_ratio > 10:
        print("   â†’ ë‹¤ì¤‘ ë¶ˆëŸ‰ì´ ìœ ì˜ë¯¸í•˜ê²Œ ì¡´ì¬ â†’ Co-occurrence ëª¨ë¸ë§ í•„ìš”")
    
    # ê°€ì¥ ê°•í•œ ìƒê´€ê´€ê³„ ì°¾ê¸°
    max_cond_prob = 0
    max_pair = None
    for i in range(4):
        for j in range(4):
            if i != j:
                prob = df_cond.iloc[i, j]
                if prob > max_cond_prob:
                    max_cond_prob = prob
                    max_pair = (i+1, j+1)
    
    if max_pair:
        print(f"\n2. ê°€ì¥ ê°•í•œ ì¡°ê±´ë¶€ í™•ë¥ :")
        print(f"   P(Class_{max_pair[1]} | Class_{max_pair[0]}) = {max_cond_prob:.3f}")
        print(f"   â†’ Class_{max_pair[0]} ë¶ˆëŸ‰ì´ ìˆì„ ë•Œ Class_{max_pair[1]}ë„ {max_cond_prob*100:.1f}% í™•ë¥ ë¡œ ì¡´ì¬")
    
    print("\n3. ì œì•ˆ ì—°êµ¬ ë°©í–¥:")
    print("   - Co-occurrence ê¸°ë°˜ ì†ì‹¤ í•¨ìˆ˜ ì„¤ê³„")
    print("   - ì¡°ê±´ë¶€ ë¶ˆëŸ‰ ì˜ˆì¸¡ ëª¨ë“ˆ")
    print("   - Graph Neural Network ê¸°ë°˜ ê´€ê³„ ëª¨ë¸ë§")
    
    return summary


# =============================================================================
# CLI ì‹¤í–‰
# =============================================================================
if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Severstal Steel Defect ë‹¤ì¤‘ ë¶ˆëŸ‰ Co-occurrence ë¶„ì„",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python analyze_severstal.py --data_root /path/to/severstal_data
  
ë°ì´í„° ë‹¤ìš´ë¡œë“œ:
  kaggle competitions download -c severstal-steel-defect-detection
        """
    )
    
    parser.add_argument(
        '--data_root', 
        type=str, 
        required=True,
        help='Severstal ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ (train.csvê°€ ìˆëŠ” í´ë”)'
    )
    
    parser.add_argument(
        '--output', 
        type=str, 
        default='severstal_results',
        help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: severstal_results)'
    )
    
    args = parser.parse_args()
    
    main(args.data_root, args.output)
